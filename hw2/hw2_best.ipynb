{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(predict):\n",
    "    return(1/(1 + np.exp(-predict)))\n",
    "\n",
    "def loss(y, yhat):\n",
    "    return -np.mean(y*np.log(yhat)) + (1-y)*np.log(1-yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scaler():\n",
    "    def fit(self, xss, dummy_columns, numeric_columns):\n",
    "        \n",
    "        self.numeric_columns = numeric_columns\n",
    "        self.dummy_columns = dummy_columns\n",
    "        \n",
    "        ## process numeric matrix\n",
    "        numeric_vector = xss.iloc[:,numeric_columns]\n",
    "        self.mean = np.mean(numeric_vector)\n",
    "        self.std = np.std(numeric_vector)\n",
    "        \n",
    "        ## process dummy matrix\n",
    "        dummy_vector = xss.iloc[:,dummy_columns]\n",
    "        self.proportion = np.mean(dummy_vector)\n",
    "        \n",
    "    def transform_dummy(self,xs,proportion):\n",
    "        trans_xs = [1 - proportion if x == 1 else proportion for x in xs]\n",
    "        return trans_xs\n",
    "        \n",
    "    def transform_numeric(self,xs, mean, std):\n",
    "        xs = (xs-mean)/std\n",
    "        return(xs)\n",
    "\n",
    "    def transform(self, xss):\n",
    "        row, col = xss.shape\n",
    "        df = []\n",
    "        for c in range(col):\n",
    "            xs = xss.iloc[:,c]\n",
    "            if c in self.dummy_columns:\n",
    "                dff = xs\n",
    "                \n",
    "                idx = self.dummy_columns.index(c)\n",
    "                proportion = self.proportion[idx]\n",
    "                dff = self.transform_dummy(xs,proportion)\n",
    "            else:\n",
    "                idx = self.numeric_columns.index(c)\n",
    "                mean = self.mean[idx]\n",
    "                std = self.std[idx]\n",
    "                dff = self.transform_numeric(xs,mean,std)\n",
    "                \n",
    "            df.append(dff)\n",
    "        df = (np.column_stack(df))\n",
    "        return(pd.DataFrame(df))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dummy_id(X_train):\n",
    "    df = X_train.describe().T\n",
    "    row, col = df.shape\n",
    "    dummy_columns = []\n",
    "    numeric_columns = []\n",
    "    for r in range(row):\n",
    "        if df['max'][r] <= 1 and df['min'][r] >= 0:\n",
    "            dummy_columns.append(r)\n",
    "        else:\n",
    "            numeric_columns.append(r)\n",
    "    \n",
    "    return({'dummy_columns': dummy_columns,\n",
    "            'numeric_columns': numeric_columns})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData():\n",
    "    X_train = pd.read_csv('data/X_train')\n",
    "    X_test = pd.read_csv('data/X_test')\n",
    "    Y_train = pd.read_csv('data/Y_train')\n",
    "    \n",
    "    return {'X_train':X_train, 'Y_train':Y_train, 'X_test': X_test}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = getData()\n",
    "X_train = res['X_train']\n",
    "Y_train = res['Y_train']\n",
    "X_test = res['X_test']\n",
    "\n",
    "res = get_dummy_id(X_train)\n",
    "dummy_columns = res['dummy_columns']\n",
    "numeric_columns = res['numeric_columns']\n",
    "\n",
    "scaler = Scaler()\n",
    "scaler.fit(X_train, dummy_columns, numeric_columns)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tuning the hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[label    0.864513\n",
      "dtype: float64, label    0.864636\n",
      "dtype: float64, label    0.864513\n",
      "dtype: float64, label    0.864513\n",
      "dtype: float64, label    0.86439\n",
      "dtype: float64, label    0.863899\n",
      "dtype: float64, label    0.864267\n",
      "dtype: float64, label    0.864144\n",
      "dtype: float64, label    0.864144\n",
      "dtype: float64, label    0.864022\n",
      "dtype: float64, label    0.863899\n",
      "dtype: float64, label    0.863776\n",
      "dtype: float64, label    0.864022\n",
      "dtype: float64]\n",
      "[label    0.875471\n",
      "dtype: float64, label    0.875676\n",
      "dtype: float64, label    0.875266\n",
      "dtype: float64, label    0.875184\n",
      "dtype: float64, label    0.875266\n",
      "dtype: float64, label    0.875143\n",
      "dtype: float64, label    0.87498\n",
      "dtype: float64, label    0.874898\n",
      "dtype: float64, label    0.874816\n",
      "dtype: float64, label    0.874898\n",
      "dtype: float64, label    0.875143\n",
      "dtype: float64, label    0.875307\n",
      "dtype: float64, label    0.875512\n",
      "dtype: float64]\n"
     ]
    }
   ],
   "source": [
    "hyper = range(80,106,2)\n",
    "his_train = []\n",
    "his_test = []\n",
    "\n",
    "for h in hyper:\n",
    "    #clf = LogisticRegression(random_state=0, solver='newton-cg')\n",
    "    regr = RandomForestRegressor(max_depth=10, random_state=0,\n",
    "                            n_estimators=h)\n",
    "    \n",
    "    regr.fit(x_train, y_train.values.ravel())\n",
    "    y_pred = regr.predict(x_train)\n",
    "    value =[ 0 if i <= 0.5 else 1 for i in y_pred]\n",
    "    acc = np.mean(value == y_train)\n",
    "    his_train.append(acc)\n",
    "    \n",
    "    y_pred = regr.predict(x_test)\n",
    "    value =[ 0 if i <= 0.5 else 1 for i in y_pred]\n",
    "    acc = np.mean(value == y_test)\n",
    "    his_test.append(acc)\n",
    "    \n",
    "    clear_output()\n",
    "    print(his_test)\n",
    "    print(his_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## implement random forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(max_depth=10, random_state=0,\n",
    "                            n_estimators=82)\n",
    "\n",
    "regr.fit(X_train,Y_train.values.ravel())\n",
    "y_pred = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## implement logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0, solver='newton-cg').fit(X_train, Y_train.values.ravel())\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## implement pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## submit answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = 'random-forest-10-82'\n",
    "row , col = X_test.shape\n",
    "ans = []\n",
    "for i in range((row)):\n",
    "    val = int(y_pred[i] > 0.5)\n",
    "    ans.append([i+1 ,val])\n",
    "\n",
    "ans = pd.DataFrame(ans,columns=['id', 'label'])\n",
    "ans.to_csv('data/'+ outfile +'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9991401019593391, 0.9834776733615871, 0.9833548307843498)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab1 = (pd.read_csv('data/random-forest-10-80.csv')['label'])\n",
    "lab2 = (pd.read_csv('data/random-forest-10-82.csv')['label'])\n",
    "lab3 = (pd.read_csv('data/random.csv')['label'])\n",
    "\n",
    "np.mean(lab1==lab2), np.mean(lab2==lab3),np.mean(lab1==lab3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
