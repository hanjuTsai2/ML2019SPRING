{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the training data and import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "class standardScaler():\n",
    "    def fit(self, xss):\n",
    "        self.mean = np.mean(xss, axis=0)\n",
    "        self.sd = np.std(xss, axis=0)\n",
    "\n",
    "    def transform(self, xss):\n",
    "        xss = (xss-self.mean)/(self.sd)\n",
    "        return(xss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures \n",
    "def polyTransform(xss):\n",
    "#     xss = np.column_stack([xss, xss**2])\n",
    "    poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "    xss = poly.fit_transform(xss)\n",
    "    return(xss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the data 9 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_Initial_Parameters(outliers=[], scale=True):\n",
    "    # read data\n",
    "    data = pd.read_csv('data/train.csv', encoding='Big5')\n",
    "    data = data.replace('NR', '0')\n",
    "    data = np.array(data)\n",
    "    \n",
    "    # feature variable\n",
    "    hour = 9\n",
    "    feature_num = 18\n",
    "    day_per_month = 20\n",
    "    per_month_row = feature_num * day_per_month\n",
    "    total_month = int(len(data)/per_month_row) \n",
    "    \n",
    "    month_data = []\n",
    "    for i in range(total_month):\n",
    "        l = data[i * per_month_row: i * per_month_row  + per_month_row]\n",
    "        month_data.append(l)  \n",
    "\n",
    "    hour_data = []\n",
    "    for i in range(len(month_data)):\n",
    "        tmp = []\n",
    "        for j in range(len(month_data[i])):\n",
    "            tmp.append(month_data[i][j])\n",
    "        hour_data.append(tmp)\n",
    "\n",
    "    total = []\n",
    "    for i in range(len(hour_data)):\n",
    "        df = pd.DataFrame(hour_data[i])\n",
    "        row, col = df.shape\n",
    "        tmp = None\n",
    "        for j in range(day_per_month):\n",
    "            per_day = df.iloc[j*feature_num:j*feature_num+feature_num,:]\n",
    "            per_day = per_day.iloc[:,3:]\n",
    "\n",
    "            if tmp is not None:\n",
    "                tmp = pd.concat([tmp.reset_index(drop=True), per_day.reset_index(drop=True)], axis=1, ignore_index=True)\n",
    "            else:\n",
    "                tmp = pd.DataFrame(per_day)   \n",
    "\n",
    "        total.append(tmp)\n",
    "        \n",
    "    xss = []\n",
    "    yss = []\n",
    "    ori_xss = []\n",
    "    ori_yss = []\n",
    "\n",
    "    for i in range(len(total)):\n",
    "        df = total[i]\n",
    "        row, col = df.shape\n",
    "        for j in range(col-hour):\n",
    "            xs = df.iloc[:,j:j+hour]\n",
    "            xs = xs.values.ravel()\n",
    "            ys = float(df.iloc[9,j+hour])\n",
    "\n",
    "            ori_xss.append(xs)\n",
    "            ori_yss.append(float(ys))\n",
    "\n",
    "            if(ys < 0):\n",
    "                continue\n",
    "                \n",
    "            xss.append(xs)\n",
    "            yss.append(float(ys))\n",
    "\n",
    "    xss = pd.DataFrame(xss).values.astype(np.float)\n",
    "    yss = np.array(yss)\n",
    "    ori_xss = pd.DataFrame(ori_xss).values.astype(np.float)\n",
    "    ori_yss = np.array(ori_yss)\n",
    "\n",
    "    if scale:\n",
    "        ## feature scaling\n",
    "        scaler = standardScaler()\n",
    "        scaler.fit(xss)\n",
    "        xss = scaler.transform(xss)\n",
    "        row, col = xss.shape\n",
    "    \n",
    "    if outliers:\n",
    "        xss = np.array([ xss[i] for i in range(len(xss)) if i not in outlier])\n",
    "        yss = np.array([ yss[i] for i in range(len(yss)) if i not in outlier])\n",
    "        \n",
    "    return ({'xss': xss, 'yss': yss, 'ori_xss': ori_xss, 'ori_yss': ori_yss, 'scaler': scaler})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor    \n",
    "def calculate_vif_(X, thresh=150):\n",
    "    cols = X.columns\n",
    "    variables = np.arange(X.shape[1])\n",
    "    dropped=True\n",
    "    while dropped:\n",
    "        dropped=False\n",
    "        c = X[cols[variables]].values\n",
    "        vif = [variance_inflation_factor(c, ix) for ix in np.arange(c.shape[1])]\n",
    "\n",
    "        maxloc = vif.index(max(vif))\n",
    "        if max(vif) > thresh:\n",
    "            variables = np.delete(variables, maxloc)\n",
    "            dropped=True\n",
    "\n",
    "    print('Remaining variables:')\n",
    "    print(X.columns[variables])\n",
    "    return (X.columns[variables], X[cols[variables]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5584, 162)\n"
     ]
    }
   ],
   "source": [
    "param = generate_Initial_Parameters(outliers=outlier)\n",
    "xss = param['xss']\n",
    "yss = param['yss']\n",
    "scaler = param['scaler']\n",
    "print(xss.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5584, 324)\n"
     ]
    }
   ],
   "source": [
    "xss = polyTransform(xss)\n",
    "print(xss.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = calculate_vif_(X_train)\n",
    "selected_var, xss = res[0], res[1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select only past pm2.5 as factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_var = np.array([  0,   2,   4,   7,   8,   9,  10,  11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29, 30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42, 43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77, 78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90, 91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,  156, 157, 158, 159, 160, 161]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_var = np.array([(i)*feature_num +9 for i in range(9)]\n",
    "X_train = pd.DataFrame(xss)\n",
    "X_train = X_train[selected_var]\n",
    "xss = X_train.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(xss, yss, test_size=0.2, random_state=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model. Don't forget to remove the clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "# def gradientDescent(xss, yss , alpha):\n",
    "#     lr = 1\n",
    "#     max_iter = 10 ** 3\n",
    "#     epochs = 200\n",
    "    \n",
    "#     ## get bias\n",
    "#     xss = np.column_stack(([1] * len(xss) ,xss))\n",
    "#     num = xss.shape[1]\n",
    "#     w = np.zeros(num)\n",
    "#     w_lr = np.zeros(num)\n",
    "    \n",
    "#     for t in range(epochs):\n",
    "#         w_grad = None\n",
    "#         for m in range(max_iter):\n",
    "#             predict = np.dot(xss,w)\n",
    "#             w_grad = -(2 * np.dot(xss.T,(yss - predict))) + (alpha * np.sum(w**2) * 2)\n",
    "#             w_lr = w_lr + w_grad ** 2\n",
    "#             w = w - lr/np.sqrt(w_lr) * w_grad\n",
    "\n",
    "#         clear_output()\n",
    "#         print(t)\n",
    "#         print(np.sqrt(np.mean([ x*x for x in (yss-predict)])))\n",
    "        \n",
    "#     return (w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "def gradientDescent(xss, yss , alpha):\n",
    "    xss = np.column_stack(([1] * len(xss) ,xss))\n",
    "    AtA =(alpha * np.identity(len(xss[0])) + np.dot(xss.T, xss)) \n",
    "    inv = np.linalg.inv(AtA)\n",
    "    w =  np.dot(inv, xss.T)\n",
    "    w = np.dot(w,yss)\n",
    "    return(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha_list = [10, 6, 5, 4, 3, 2, 1, 0.5, 0.3, 0.2, 0.1, 0.01, 0.001, 0.0001]\n",
    "alpha_list = [0]\n",
    "his = []\n",
    "for alpha in alpha_list:\n",
    "    w = gradientDescent(X_train, Y_train, alpha)\n",
    "    xss_tmp = np.column_stack(([1] * len(X_test) ,X_test))\n",
    "    yss_tmp = Y_test\n",
    "\n",
    "    predict = np.dot(xss_tmp ,w)\n",
    "\n",
    "    rmse = (np.sqrt(np.mean([ x*x for x in (yss_tmp-predict)])))\n",
    "    his.append(rmse)\n",
    "    \n",
    "print(his)\n",
    "print(his.index(min(his)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = gradientDescent(xss, yss, alpha = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/test.csv', encoding='Big5', header=None)\n",
    "test = test.replace('NR', '0')\n",
    "file = '0306-4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "dic = {'w': w, 'scaler': scaler, 'selected_var' : selected_var, 'alpha' : alpha}\n",
    "with open('model/'+file+'.pkl', 'wb') as f:\n",
    "    pickle.dump(dic, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('model/0306-2.pkl', 'rb') as f:\n",
    "#     dic = pickle.load(f)\n",
    "\n",
    "# w = dic['w']\n",
    "# scaler = dic['scaler']\n",
    "# selected_var = dic['selected_var']\n",
    "\n",
    "ans = pd.read_csv('data/sampleSubmission.csv', encoding='Big5')\n",
    "test_feature = 18\n",
    "total_test = []\n",
    "row, col = test.shape\n",
    "test_number = int(row/test_feature)\n",
    "\n",
    "for i in range(test_number):\n",
    "    df = test.iloc[i*test_feature:(i+1)*test_feature, 2:]\n",
    "    xs = df.values.ravel().astype(np.float)\n",
    "    xs = (scaler.transform([xs])[0])\n",
    "    xs = np.array([[xs[i] for i in range(len(xs)) if i in selected_var]])\n",
    "    xs = polyTransform(xs)[0]\n",
    "    xs = np.concatenate(([1], xs))\n",
    "    val = np.dot(xs,w)\n",
    "#     val = (round(val,2))\n",
    "    ans.iloc[i,1] = val\n",
    "    \n",
    "ans.to_csv('data/'+file+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# with open('model/0304-3.pkl', 'rb') as f:\n",
    "# with open('model/0305-1.pkl', 'rb') as f:\n",
    "#     dic = pickle.load(f)\n",
    "\n",
    "# w = dic['w']\n",
    "# scaler = dic['scaler']\n",
    "# selected_var = dic['selected_var']\n",
    "his = []\n",
    "his_train = []\n",
    "alphas = np.logspace(-5, 5, 5)\n",
    "min_rmse = 10000\n",
    "\n",
    "param = generate_Initial_Parameters(outliers=[])\n",
    "xss = param['xss']\n",
    "yss = param['yss']\n",
    "scaler = param['scaler']\n",
    "xss = xss[:,selected_var]\n",
    "xss = polyTransform(xss)\n",
    "res = {'w' : [], 'alpha': 0, 'k': -1 }\n",
    "\n",
    "for m in range(len(alphas)):\n",
    "    for k in range(10,50,5):\n",
    "        alpha = alphas[m]\n",
    "        if k % 10 == 0:\n",
    "            clear_output()\n",
    "\n",
    "        ## take all \n",
    "        param = generate_Initial_Parameters()\n",
    "        xss = param['xss']\n",
    "        yss = param['yss']\n",
    "\n",
    "        xss = xss[:,selected_var]\n",
    "        xss = polyTransform(xss)\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(xss, yss, test_size=0.2, random_state=28)\n",
    "        w = gradientDescent(X_train, Y_train, alpha = alpha)\n",
    "        \n",
    "        val = np.column_stack(([1] * len(X_train) ,X_train))\n",
    "        predict = np.dot(val,w)\n",
    "        predict = np.array([round(i,0) for i in predict])\n",
    "        Y_train = np.array(Y_train)\n",
    "\n",
    "        error = (predict-Y_train)\n",
    "        rmse = np.sqrt(np.mean(error**2))\n",
    "        his_train.append(rmse)\n",
    "        print('training rmse =', rmse, end=',')\n",
    "        outlier = [ i for i in range(len(error)) if abs(error[i]) >= k]\n",
    "\n",
    "        X_train = [ X_train[i] for i in range(len(X_train)) if i not in outlier]\n",
    "        Y_train = [ Y_train[i] for i in range(len(Y_train)) if i not in outlier]\n",
    "        \n",
    "        w = gradientDescent(X_train, Y_train, alpha = alpha)\n",
    "        val = np.column_stack(([1] * len(X_test) ,X_test))\n",
    "        predict = np.dot(val,w)\n",
    "        predict = np.array([round(i,0) for i in predict])\n",
    "        Y_test = np.array(Y_test)\n",
    "        \n",
    "        error = (predict-Y_test)\n",
    "        rmse = np.sqrt(np.mean(error**2))\n",
    "        \n",
    "        min_rmse = min(rmse, min_rmse)\n",
    "        if min_rmse == rmse:\n",
    "            res['w'] = w\n",
    "            res['alpha'] = alpha\n",
    "            res['k'] = k\n",
    "            \n",
    "        print('rmse =', rmse)\n",
    "        his.append(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(his[:20])\n",
    "plt.plot(his_train[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.06482835,  5.36550241],\n",
       "       [ 6.05694702,  5.36550241],\n",
       "       [ 6.06916975,  5.36550241],\n",
       "       [ 6.04809592,  5.36550241],\n",
       "       [ 6.02791127,  5.36550241],\n",
       "       [ 6.02791127,  5.36550241],\n",
       "       [ 6.02791127,  5.36550241],\n",
       "       [ 6.06482835,  5.36550241],\n",
       "       [ 6.05694702,  5.36550241],\n",
       "       [ 6.06916975,  5.36550241],\n",
       "       [ 6.04809592,  5.36550241],\n",
       "       [ 6.02791127,  5.36550241],\n",
       "       [ 6.02791127,  5.36550241],\n",
       "       [ 6.02791127,  5.36550241],\n",
       "       [ 6.05628363,  5.36392131],\n",
       "       [ 6.05451425,  5.36392131],\n",
       "       [ 6.0634296 ,  5.36392131],\n",
       "       [ 6.04248352,  5.36392131],\n",
       "       [ 6.02805939,  5.36392131],\n",
       "       [ 6.02805939,  5.36392131],\n",
       "       [ 6.02805939,  5.36392131],\n",
       "       [ 7.55852168,  6.55503827],\n",
       "       [ 7.37206358,  6.55503827],\n",
       "       [ 7.33995913,  6.55503827],\n",
       "       [ 7.33995913,  6.55503827],\n",
       "       [ 7.34871223,  6.55503827],\n",
       "       [ 7.36921686,  6.55503827],\n",
       "       [ 7.35138471,  6.55503827],\n",
       "       [15.89822542, 13.26251936],\n",
       "       [15.26293363, 13.26251936],\n",
       "       [14.83513566, 13.26251936],\n",
       "       [14.48567642, 13.26251936],\n",
       "       [14.29972527, 13.26251936],\n",
       "       [14.14835301, 13.26251936],\n",
       "       [14.04816333, 13.26251936]])"
      ]
     },
     "execution_count": 639,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.column_stack([his,his_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (5571,150) and (299,) not aligned: 150 (dim 1) != 299 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-648-ce8994e8a2ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumn_stack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxss\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mxss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[0myss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (5571,150) and (299,) not aligned: 150 (dim 1) != 299 (dim 0)"
     ]
    }
   ],
   "source": [
    "k=res['k']\n",
    "al=res['alpha']\n",
    "w = res['w']\n",
    "\n",
    "param = generate_Initial_Parameters(outliers=[])\n",
    "xss = param['xss']\n",
    "xss = xss[:,selected_var]\n",
    "xss = polyTransform(xss)\n",
    "yss = param['yss']\n",
    "scaler = param['scaler']\n",
    "\n",
    "val = np.column_stack([([1] * len(xss)) , xss])\n",
    "predict = np.dot(val,w)\n",
    "predict = np.array([round(i,0) for i in predict])\n",
    "yss = np.array(yss)\n",
    "error = (predict-yss)\n",
    "outlier = [ i for i in range(len(error)) if abs(error[i]) >= k]\n",
    "print(len(outlier))\n",
    "\n",
    "param = generate_Initial_Parameters(outliers=outlier)\n",
    "xss = param['xss']\n",
    "xss = xss[:,selected_var]\n",
    "yss = param['yss']\n",
    "scaler = param['scaler']\n",
    "\n",
    "val = np.column_stack(([1] * len(xss) ,xss))\n",
    "predict = np.dot(val,w)\n",
    "predict = np.array([round(i,0) for i in predict])\n",
    "yss = np.array(yss)\n",
    "w = gradientDescent(xss, yss , alpha = 10)\n",
    "print(len(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error num 26\n",
      "5574\n"
     ]
    }
   ],
   "source": [
    "alpha = res['alpha']\n",
    "\n",
    "w = gradientDescent(xss, yss, alpha = alpha)\n",
    "        \n",
    "## take all \n",
    "param = generate_Initial_Parameters()\n",
    "xss = param['xss']\n",
    "yss = param['yss']\n",
    "\n",
    "xss = xss[:,selected_var]\n",
    "xss = polyTransform(xss)\n",
    "\n",
    "val = np.column_stack(([1] * len(xss) ,xss))\n",
    "predict = np.dot(val,w)\n",
    "predict = [round(i,0) for i in predict]\n",
    "\n",
    "error = (predict-yss)\n",
    "outlier = [ i for i in range(len(error)) if abs(error[i]) >= 20]\n",
    "print('error num', len(outlier))\n",
    "\n",
    "xss = [ xss[i] for i in range(len(xss)) if i not in outlier]\n",
    "yss = [ yss[i] for i in range(len(yss)) if i not in outlier]\n",
    "\n",
    "print(len(xss))\n",
    "xss = pd.DataFrame(xss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd1 = pd.read_csv('data/0305-3.csv')\n",
    "pd2 = pd.read_csv('data/0305-1.csv')\n",
    "ans['value'] = (pd1['value'] + pd2['value'])/2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans.to_csv('data/0306-5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
