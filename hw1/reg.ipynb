{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the training data and import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "class standardScaler():\n",
    "    def fit(self, xss):\n",
    "        self.mean = np.mean(xss, axis=0)\n",
    "        self.sd = np.std(xss, axis=0)\n",
    "\n",
    "    def transform(self, xss):\n",
    "        xss = (xss-self.mean)/(self.sd)\n",
    "        return(xss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures \n",
    "def polyTransform(xss):\n",
    "#     xss = np.column_stack([xss, xss**2])\n",
    "    poly = PolynomialFeatures(degree=2, interaction_only=False, include_bias=False)\n",
    "    xss = poly.fit_transform(xss)\n",
    "    return(xss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the data 9 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_Initial_Parameters(outliers=[],scale=True):\n",
    "    # read data\n",
    "    data = pd.read_csv('data/train.csv', encoding='Big5')\n",
    "    data = data.replace('NR', '0')\n",
    "    data = np.array(data)\n",
    "    \n",
    "    # feature variable\n",
    "    hour = 9\n",
    "    feature_num = 18\n",
    "    day_per_month = 20\n",
    "    per_month_row = feature_num * day_per_month\n",
    "    total_month = int(len(data)/per_month_row) \n",
    "    \n",
    "    month_data = []\n",
    "    for i in range(total_month):\n",
    "        l = data[i * per_month_row: i * per_month_row  + per_month_row]\n",
    "        month_data.append(l)  \n",
    "\n",
    "    hour_data = []\n",
    "    for i in range(len(month_data)):\n",
    "        tmp = []\n",
    "        for j in range(len(month_data[i])):\n",
    "            tmp.append(month_data[i][j])\n",
    "        hour_data.append(tmp)\n",
    "\n",
    "    total = []\n",
    "    for i in range(len(hour_data)):\n",
    "        df = pd.DataFrame(hour_data[i])\n",
    "        row, col = df.shape\n",
    "        tmp = None\n",
    "        for j in range(day_per_month):\n",
    "            per_day = df.iloc[j*feature_num:j*feature_num+feature_num,:]\n",
    "            per_day = per_day.iloc[:,3:]\n",
    "\n",
    "            if tmp is not None:\n",
    "                tmp = pd.concat([tmp.reset_index(drop=True), per_day.reset_index(drop=True)], axis=1, ignore_index=True)\n",
    "            else:\n",
    "                tmp = pd.DataFrame(per_day)   \n",
    "\n",
    "        total.append(tmp)\n",
    "        \n",
    "    xss = []\n",
    "    yss = []\n",
    "    ori_xss = []\n",
    "    ori_yss = []\n",
    "\n",
    "    for i in range(len(total)):\n",
    "        df = total[i]\n",
    "        row, col = df.shape\n",
    "        for j in range(col-hour):\n",
    "            xs = df.iloc[:,j:j+hour]\n",
    "            xs = xs.values.ravel()\n",
    "            ys = float(df.iloc[9,j+hour])\n",
    "\n",
    "            ori_xss.append(xs)\n",
    "            ori_yss.append(float(ys))\n",
    "\n",
    "            if(ys < 0):\n",
    "                continue\n",
    "                \n",
    "            xss.append(xs)\n",
    "            yss.append(float(ys))\n",
    "\n",
    "    xss = pd.DataFrame(xss).values.astype(np.float)\n",
    "    yss = np.array(yss)\n",
    "    ori_xss = pd.DataFrame(ori_xss).values.astype(np.float)\n",
    "    ori_yss = np.array(ori_yss)\n",
    "\n",
    "    if scale:\n",
    "        ## feature scaling\n",
    "        scaler = standardScaler()\n",
    "        scaler.fit(xss)\n",
    "        xss = scaler.transform(xss)\n",
    "        row, col = xss.shape\n",
    "    \n",
    "    if outliers:\n",
    "        xss = np.array([ xss[i] for i in range(len(xss)) if i not in outlier])\n",
    "        yss = np.array([ yss[i] for i in range(len(yss)) if i not in outlier])\n",
    "        \n",
    "    return ({'xss': xss, 'yss': yss, 'ori_xss': ori_xss, 'ori_yss': ori_yss, 'scaler': scaler})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor    \n",
    "def calculate_vif_(X, thresh=150):\n",
    "    cols = X.columns\n",
    "    variables = np.arange(X.shape[1])\n",
    "    dropped=True\n",
    "    while dropped:\n",
    "        dropped=False\n",
    "        c = X[cols[variables]].values\n",
    "        vif = [variance_inflation_factor(c, ix) for ix in np.arange(c.shape[1])]\n",
    "\n",
    "        maxloc = vif.index(max(vif))\n",
    "        if max(vif) > thresh:\n",
    "            variables = np.delete(variables, maxloc)\n",
    "            dropped=True\n",
    "\n",
    "    print('Remaining variables:')\n",
    "    print(X.columns[variables])\n",
    "    return (X.columns[variables], X[cols[variables]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4029, 162)\n"
     ]
    }
   ],
   "source": [
    "param = generate_Initial_Parameters(outliers=outlier)\n",
    "xss = param['xss']\n",
    "yss = param['yss']\n",
    "scaler = param['scaler']\n",
    "print(xss.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5518, 298)\n"
     ]
    }
   ],
   "source": [
    "xss = polyTransform(xss)\n",
    "print(xss.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = calculate_vif_(X_train)\n",
    "selected_var, xss = res[0], res[1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select only past pm2.5 as factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_var = np.array([  0,   2,   4,   7,   8,   9,  10,  11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29, 30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42, 43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77, 78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90, 91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,  156, 157, 158, 159, 160, 161]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_var = np.array([(i)*feature_num +9 for i in range(9)]\n",
    "X_train = pd.DataFrame(xss)\n",
    "X_train = X_train[selected_var]\n",
    "xss = X_train.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(xss, yss, test_size=0.2, random_state=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model. Don't forget to remove the clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "# def gradientDescent(xss, yss , alpha):\n",
    "#     lr = 1\n",
    "#     max_iter = 10 ** 3\n",
    "#     epochs = 200\n",
    "    \n",
    "#     ## get bias\n",
    "#     xss = np.column_stack(([1] * len(xss) ,xss))\n",
    "#     num = xss.shape[1]\n",
    "#     w = np.zeros(num)\n",
    "#     w_lr = np.zeros(num)\n",
    "    \n",
    "#     for t in range(epochs):\n",
    "#         w_grad = None\n",
    "#         for m in range(max_iter):\n",
    "#             predict = np.dot(xss,w)\n",
    "#             w_grad = -(2 * np.dot(xss.T,(yss - predict))) + (alpha * np.sum(w**2) * 2)\n",
    "#             w_lr = w_lr + w_grad ** 2\n",
    "#             w = w - lr/np.sqrt(w_lr) * w_grad\n",
    "\n",
    "#         clear_output()\n",
    "#         print(t)\n",
    "#         print(np.sqrt(np.mean([ x*x for x in (yss-predict)])))\n",
    "        \n",
    "#     return (w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "def gradientDescent(xss, yss , alpha):\n",
    "    xss = np.column_stack(([1] * len(xss) ,xss))\n",
    "    AtA =(alpha * np.identity(len(xss[0])) + np.dot(xss.T, xss)) \n",
    "    inv = np.linalg.inv(AtA)\n",
    "    w =  np.dot(inv, xss.T)\n",
    "    w = np.dot(w,yss)\n",
    "    return(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.915493308054814]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# alpha_list = [10, 6, 5, 4, 3, 2, 1, 0.5, 0.3, 0.2, 0.1, 0.01, 0.001, 0.0001]\n",
    "alpha_list = [0]\n",
    "his = []\n",
    "for alpha in alpha_list:\n",
    "    w = gradientDescent(X_train, Y_train, alpha)\n",
    "    xss_tmp = np.column_stack(([1] * len(X_test) ,X_test))\n",
    "    yss_tmp = Y_test\n",
    "\n",
    "    predict = np.dot(xss_tmp ,w)\n",
    "\n",
    "    rmse = (np.sqrt(np.mean([ x*x for x in (yss_tmp-predict)])))\n",
    "    his.append(rmse)\n",
    "    \n",
    "print(his)\n",
    "print(his.index(min(his)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = gradientDescent(xss, yss, alpha = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/test.csv', encoding='Big5', header=None)\n",
    "test = test.replace('NR', '0')\n",
    "file = '0306-4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "dic = {'w': w, 'scaler': scaler, 'selected_var' : selected_var, 'alpha' : alpha}\n",
    "with open('model/'+file+'.pkl', 'wb') as f:\n",
    "    pickle.dump(dic, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('model/0306-2.pkl', 'rb') as f:\n",
    "#     dic = pickle.load(f)\n",
    "\n",
    "# w = dic['w']\n",
    "# scaler = dic['scaler']\n",
    "# selected_var = dic['selected_var']\n",
    "\n",
    "ans = pd.read_csv('data/sampleSubmission.csv', encoding='Big5')\n",
    "test_feature = 18\n",
    "total_test = []\n",
    "row, col = test.shape\n",
    "test_number = int(row/test_feature)\n",
    "\n",
    "for i in range(test_number):\n",
    "    df = test.iloc[i*test_feature:(i+1)*test_feature, 2:]\n",
    "    xs = df.values.ravel().astype(np.float)\n",
    "    xs = (scaler.transform([xs])[0])\n",
    "    xs = np.array([[xs[i] for i in range(len(xs)) if i in selected_var]])\n",
    "    xs = polyTransform(xs)[0]\n",
    "    xs = np.concatenate(([1], xs))\n",
    "    val = np.dot(xs,w)\n",
    "#     val = (round(val,2))\n",
    "    ans.iloc[i,1] = val\n",
    "    \n",
    "ans.to_csv('data/'+file+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# with open('model/0304-3.pkl', 'rb') as f:\n",
    "# with open('model/0305-1.pkl', 'rb') as f:\n",
    "#     dic = pickle.load(f)\n",
    "\n",
    "# w = dic['w']\n",
    "# scaler = dic['scaler']\n",
    "# selected_var = dic['selected_var']\n",
    "his = []\n",
    "his_train = []\n",
    "alphas = np.logspace(-5, 3, 5)\n",
    "min_rmse = 10000\n",
    "\n",
    "\n",
    "param = generate_Initial_Parameters(outliers=[])\n",
    "xss = param['xss']\n",
    "yss = param['yss']\n",
    "scaler = param['scaler']\n",
    "xss = xss[:,selected_var]\n",
    "xss = polyTransform(xss)\n",
    "res = {'w' : [], 'alpha': 0, 'k': -1 }\n",
    "\n",
    "for m in range(len(alphas)):\n",
    "    for k in range(15,50,5):\n",
    "        alpha = alphas[m]\n",
    "        if k % 10 == 0:\n",
    "            clear_output()\n",
    "\n",
    "        ## take all \n",
    "        param = generate_Initial_Parameters()\n",
    "        xss = param['xss']\n",
    "        yss = param['yss']\n",
    "\n",
    "        xss = xss[:,selected_var]\n",
    "        xss = polyTransform(xss)\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(xss, yss, test_size=0.2, random_state=33)\n",
    "        w = gradientDescent(X_train, Y_train, alpha = alpha)\n",
    "        \n",
    "        val = np.column_stack(([1] * len(X_train) ,X_train))\n",
    "        predict = np.dot(val,w)\n",
    "        predict = np.array([round(i,0) for i in predict])\n",
    "        Y_train = np.array(Y_train)\n",
    "\n",
    "        error = (predict-Y_train)\n",
    "        rmse = np.sqrt(np.mean(error**2))\n",
    "        his_train.append(rmse)\n",
    "#         print('training rmse =', rmse, end=',')\n",
    "        outlier = [ i for i in range(len(error)) if abs(error[i]) >= k]\n",
    "\n",
    "        X_train = [ X_train[i] for i in range(len(X_train)) if i not in outlier]\n",
    "        Y_train = [ Y_train[i] for i in range(len(Y_train)) if i not in outlier]\n",
    "        \n",
    "        w = gradientDescent(X_train, Y_train, alpha = alpha)\n",
    "        val = np.column_stack(([1] * len(X_test) ,X_test))\n",
    "        predict = np.dot(val,w)\n",
    "        predict = np.array([round(i,0) for i in predict])\n",
    "        Y_test = np.array(Y_test)\n",
    "        \n",
    "        error = (predict-Y_test)\n",
    "        rmse = np.sqrt(np.mean(error**2))\n",
    "        \n",
    "        min_rmse = min(rmse, min_rmse)\n",
    "        if min_rmse == rmse:\n",
    "            res['w'] = w\n",
    "            res['alpha'] = alpha\n",
    "            res['k'] = k\n",
    "            \n",
    "#         print('rmse =', rmse)\n",
    "        his.append(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(his[:20])\n",
    "plt.plot(his_train[:20])\n",
    "# i = 0\n",
    "# plt.plot(his[i*8:(i+1)*8])\n",
    "# plt.plot(his_train[i*8:(i+1)*8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 15, 20, 25, 30, 35, 40, 45]"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(10,50,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.46841581, 5.66292769],\n",
       "       [5.48431204, 5.66292769],\n",
       "       [5.50219112, 5.66292769],\n",
       "       [5.48007755, 5.66292769],\n",
       "       [5.51418625, 5.66292769],\n",
       "       [5.51418625, 5.66292769],\n",
       "       [5.51418625, 5.66292769],\n",
       "       [5.46841581, 5.66292769],\n",
       "       [5.48431204, 5.66292769],\n",
       "       [5.50219112, 5.66292769],\n",
       "       [5.48007755, 5.66292769],\n",
       "       [5.51418625, 5.66292769],\n",
       "       [5.51418625, 5.66292769],\n",
       "       [5.51418625, 5.66292769],\n",
       "       [5.46857908, 5.66229698],\n",
       "       [5.48178803, 5.66229698],\n",
       "       [5.50227226, 5.66229698],\n",
       "       [5.47852952, 5.66229698],\n",
       "       [5.51588615, 5.66229698],\n",
       "       [5.51588615, 5.66229698],\n",
       "       [5.51588615, 5.66229698],\n",
       "       [5.43459487, 5.66797079],\n",
       "       [5.47608437, 5.66797079],\n",
       "       [5.47110919, 5.66797079],\n",
       "       [5.46596613, 5.66797079],\n",
       "       [5.48919393, 5.66797079],\n",
       "       [5.48919393, 5.66797079],\n",
       "       [5.48919393, 5.66797079],\n",
       "       [8.57331824, 7.88308825],\n",
       "       [8.0123231 , 7.88308825],\n",
       "       [7.79983974, 7.88308825],\n",
       "       [7.68922019, 7.88308825],\n",
       "       [7.66922188, 7.88308825],\n",
       "       [7.63275367, 7.88308825],\n",
       "       [7.61548001, 7.88308825]])"
      ]
     },
     "execution_count": 578,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.column_stack([his,his_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.14327164e+01,  9.42967919e-02,  1.77463578e-01, -3.37513246e-01,\n",
       "       -1.41598001e+00,  1.48963463e+00, -5.01948146e-01,  6.22195351e-02,\n",
       "        9.01952569e-02,  1.12970576e-01, -1.50122026e-01,  1.99187906e-01,\n",
       "       -3.36505704e-01, -3.27081288e-02,  3.12005043e-01,  6.73955916e-02,\n",
       "       -4.85585377e-02,  2.12013325e-01, -2.32487687e-01,  3.00238751e-01,\n",
       "       -1.80666205e-01,  1.68637481e-02,  3.83480525e-02,  2.95507428e-01,\n",
       "       -5.72547191e-01,  5.87278685e-01, -5.60493178e-01,  3.28772890e-01,\n",
       "        2.46536530e-01, -3.94433444e-01, -4.24959805e-01,  1.47216014e-01,\n",
       "        1.77650362e-02,  4.58895622e-02, -7.99386140e-02,  3.57781551e-01,\n",
       "       -9.36817060e-02,  1.45570388e-03, -1.98774201e-01,  2.77368106e-02,\n",
       "        9.51228082e-02,  1.16620483e-02,  3.49364882e-02, -2.00154645e-01,\n",
       "       -2.31116927e-01, -1.81887832e-01,  1.39383100e-01, -1.89915867e-01,\n",
       "       -2.94774636e-01, -1.67504589e-01,  1.49464044e+00,  1.74603863e-01,\n",
       "        1.87745487e-01, -4.43832432e-01, -9.31672581e-02, -1.37652602e-01,\n",
       "       -6.63162059e-01, -5.22473290e-01,  1.72733640e-01,  1.82840108e+00,\n",
       "       -5.60275158e-02,  3.10292247e-01, -3.87894557e-01,  7.60384467e-01,\n",
       "       -5.86399797e-01, -3.28447036e-02,  3.42800398e-01, -3.03982321e-01,\n",
       "        1.51281466e+00, -4.84206417e-01, -3.98406345e-01,  3.34470971e+00,\n",
       "       -3.57946580e+00, -5.74548382e-01,  8.04971830e+00, -8.81733677e+00,\n",
       "       -3.47286675e-01,  1.62403520e+01,  1.63932511e-01, -9.82202829e-04,\n",
       "       -1.28947290e-01,  1.12369317e-02, -1.24703360e-01,  6.09331605e-03,\n",
       "        7.44803842e-02, -1.25723178e-01, -1.21017659e-01,  1.15723256e-01,\n",
       "        9.62049486e-02,  1.23764392e-01, -2.82666356e-01, -4.91300638e-01,\n",
       "        6.47774375e-01, -1.07114189e+00,  2.20969908e-01,  4.64760167e-01,\n",
       "       -2.01495925e-01,  2.89763800e-01, -5.94135237e-03, -1.43001960e-01,\n",
       "       -1.32265263e-01,  2.61637014e-01, -3.00900145e-01,  1.39105103e-01,\n",
       "        2.81037969e-01,  8.18402814e-01, -6.08591280e-01,  3.17505367e-01,\n",
       "       -3.31105804e-01, -3.33720766e-01,  5.13978979e-01,  5.58407968e-01,\n",
       "       -2.75726709e-01,  4.14132798e-02,  1.44677723e-02,  1.29405955e-01,\n",
       "        1.73456571e-01,  2.35059087e-01, -1.55231875e-01,  2.32945951e-01,\n",
       "       -1.73489010e-01, -8.08176776e-03,  7.65719180e-02, -2.33866576e-01,\n",
       "       -4.22387436e-02, -6.28017314e-02, -7.09196833e-02,  3.09247165e-02,\n",
       "       -8.45036828e-02, -6.74226797e-03, -2.22049677e-01,  5.75632400e-02,\n",
       "       -1.96809338e-01, -3.19579978e-02,  1.07158006e-01,  1.68283524e-01,\n",
       "       -3.07086681e-02, -1.14374332e-01, -6.89113576e-02, -2.78596621e-02,\n",
       "       -2.32689411e-01, -6.62951488e-02,  9.13913046e-02,  5.38191034e-02,\n",
       "       -2.61285032e-01, -2.96881938e-02,  2.30722772e-01,  1.13720063e-02,\n",
       "       -1.83879205e-01,  9.74111471e-02])"
      ]
     },
     "execution_count": 582,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['w']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "347\n",
      "150\n"
     ]
    }
   ],
   "source": [
    "k=res['k']\n",
    "al=res['alpha']\n",
    "\n",
    "param = generate_Initial_Parameters(outliers=[])\n",
    "xss = param['xss']\n",
    "xss = xss[:,selected_var]\n",
    "yss = param['yss']\n",
    "scaler = param['scaler']\n",
    "\n",
    "val = np.column_stack([([1] * len(xss)) , xss])\n",
    "predict = np.dot(val,w)\n",
    "predict = np.array([round(i,0) for i in predict])\n",
    "yss = np.array(yss)\n",
    "error = (predict-yss)\n",
    "outlier = [ i for i in range(len(error)) if abs(error[i]) >= k]\n",
    "print(len(outlier))\n",
    "\n",
    "param = generate_Initial_Parameters(outliers=outlier)\n",
    "xss = param['xss']\n",
    "xss = xss[:,selected_var]\n",
    "yss = param['yss']\n",
    "scaler = param['scaler']\n",
    "\n",
    "val = np.column_stack(([1] * len(xss) ,xss))\n",
    "predict = np.dot(val,w)\n",
    "predict = np.array([round(i,0) for i in predict])\n",
    "yss = np.array(yss)\n",
    "w = gradientDescent(xss, yss , alpha = 10)\n",
    "print(len(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse = 9.542751549886287\n",
      "error num 1541\n",
      "4059\n"
     ]
    }
   ],
   "source": [
    "w = gradientDescent(xss, yss, alpha = alpha)\n",
    "        \n",
    "## take all \n",
    "param = generate_Initial_Parameters()\n",
    "xss = param['xss']\n",
    "yss = param['yss']\n",
    "\n",
    "xss = xss[:,selected_var]\n",
    "xss = polyTransform(xss)\n",
    "\n",
    "val = np.column_stack(([1] * len(xss) ,xss))\n",
    "predict = np.dot(val,w)\n",
    "predict = [round(i,0) for i in predict]\n",
    "\n",
    "error = (predict-yss)\n",
    "rmse =  np.sqrt(np.mean(error ** 2)) \n",
    "min_rmse = min(min_rmse,rmse)\n",
    "\n",
    "\n",
    "if min_rmse == rmse:\n",
    "    ans['w'] = w\n",
    "    ans['alpha'] = alpha\n",
    "    ans['outlier'] = outlier\n",
    "print('rmse =', rmse)\n",
    "his.append(rmse)\n",
    "\n",
    "outlier = [ i for i in range(len(error)) if abs(error[i]) >= k]\n",
    "print('error num', len(outlier))\n",
    "\n",
    "xss = [ xss[i] for i in range(len(xss)) if i not in outlier]\n",
    "yss = [ yss[i] for i in range(len(yss)) if i not in outlier]\n",
    "\n",
    "print(len(xss))\n",
    "xss = pd.DataFrame(xss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
