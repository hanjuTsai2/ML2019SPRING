{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the training data and import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class standardScaler():\n",
    "    def fit(self, xss):\n",
    "        self.mean = np.mean(xss, axis=0)\n",
    "        self.sd = np.std(xss, axis=0)\n",
    "\n",
    "    def transform(self, xss):\n",
    "        xss = (xss-self.mean)/(self.sd)\n",
    "        return(xss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/train.csv', encoding='Big5')\n",
    "data = data.replace('NR', '0')\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hour = 9\n",
    "feature_num = 18\n",
    "day_per_month = 20\n",
    "per_month_row = feature_num * day_per_month\n",
    "total_month = int(len(data)/per_month_row) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the data 9 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_data = []\n",
    "for i in range(total_month):\n",
    "    l = data[i * per_month_row: i * per_month_row  + per_month_row]\n",
    "    month_data.append(l)  \n",
    "\n",
    "hour_data = []\n",
    "for i in range(len(month_data)):\n",
    "    tmp = []\n",
    "    for j in range(len(month_data[i])):\n",
    "        tmp.append(month_data[i][j])\n",
    "    hour_data.append(tmp)\n",
    "    \n",
    "total = []\n",
    "for i in range(len(hour_data)):\n",
    "    df = pd.DataFrame(hour_data[i])\n",
    "    row, col = df.shape\n",
    "    tmp = None\n",
    "    for j in range(day_per_month):\n",
    "        per_day = df.iloc[j*feature_num:j*feature_num+feature_num,:]\n",
    "        per_day = per_day.iloc[:,3:]\n",
    "        \n",
    "        if tmp is not None:\n",
    "            tmp = pd.concat([tmp.reset_index(drop=True), per_day.reset_index(drop=True)], axis=1, ignore_index=True)\n",
    "        else:\n",
    "            tmp = pd.DataFrame(per_day)   \n",
    "     \n",
    "    total.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "xss = []\n",
    "yss = []\n",
    "ori_xss = []\n",
    "ori_yss = []\n",
    "\n",
    "for i in range(len(total)):\n",
    "    df = total[i]\n",
    "    row, col = df.shape\n",
    "    for j in range(col-hour):\n",
    "        xs = df.iloc[:,j:j+hour]\n",
    "        xs = xs.values.ravel()\n",
    "        ys = float(df.iloc[9,j+hour])\n",
    "       \n",
    "        ori_xss.append(xs)\n",
    "        ori_yss.append(float(ys))\n",
    "        \n",
    "        if(ys < 0):\n",
    "            continue \n",
    "        xss.append(xs)\n",
    "        yss.append(float(ys))\n",
    "        \n",
    "xss = pd.DataFrame(xss).values.astype(np.float)\n",
    "yss = np.array(yss)\n",
    "ori_xss = pd.DataFrame(ori_xss).values.astype(np.float)\n",
    "ori_yss = np.array(ori_yss)\n",
    "\n",
    "## feature scaling\n",
    "scaler = standardScaler()\n",
    "scaler.fit(xss)\n",
    "xss = scaler.transform(xss)\n",
    "row, col = xss.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor    \n",
    "def calculate_vif_(X, thresh=20):\n",
    "    cols = X.columns\n",
    "    variables = np.arange(X.shape[1])\n",
    "    dropped=True\n",
    "    while dropped:\n",
    "        dropped=False\n",
    "        c = X[cols[variables]].values\n",
    "        vif = [variance_inflation_factor(c, ix) for ix in np.arange(c.shape[1])]\n",
    "\n",
    "        maxloc = vif.index(max(vif))\n",
    "        if max(vif) > thresh:\n",
    "            variables = np.delete(variables, maxloc)\n",
    "            dropped=True\n",
    "\n",
    "    print('Remaining variables:')\n",
    "    print(X.columns[variables])\n",
    "    return (X.columns[variables], X[cols[variables]])\n",
    "\n",
    "X_train = pd.DataFrame(xss)\n",
    "res = calculate_vif_(X_train)\n",
    "selected_var , xss = res[0], res[1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select only past pm2.5 as factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_var = np.array([  0,   2,   4,   7,   8,   9,  10,  11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29, 30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42, 43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77, 78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90, 91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,  156, 157, 158, 159, 160, 161]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_var = np.array([(i)*feature_num +9 for i in range(9)])\n",
    "X_train = pd.DataFrame(xss)\n",
    "X_train = X_train[selected_var]\n",
    "xss = X_train.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model. Don't forget to remove the clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "max_iter = 10 ** 3\n",
    "epochs = 10 ** 3\n",
    "lr = 1\n",
    "\n",
    "xss = np.column_stack(([1] * len(xss) ,xss))\n",
    "\n",
    "num = xss.shape[1]\n",
    "w = np.zeros(num)\n",
    "w_lr = np.zeros(num)\n",
    "\n",
    "for t in range(epochs):\n",
    "    w_grad = None\n",
    "    for m in range(max_iter):\n",
    "        predict = np.dot(xss,w)\n",
    "        w_grad = -(2 * np.dot(xss.T,(yss - predict)))\n",
    "        w_lr = w_lr + w_grad ** 2\n",
    "        w = w - lr/np.sqrt(w_lr) * w_grad\n",
    "        \n",
    "    clear_output()\n",
    "    print(t)\n",
    "    print(np.sqrt(np.mean([ x*x for x in (yss-predict)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.693017905034071\n"
     ]
    }
   ],
   "source": [
    "ori_xss = scaler.transform(ori_xss)\n",
    "ori_xss = (ori_xss[:,selected_var])\n",
    "ori_xss = np.column_stack(([1] * len(ori_xss) ,ori_xss))\n",
    "predict = np.dot(ori_xss,w)\n",
    "print(np.sqrt(np.mean([ x*x for x in (ori_yss-predict)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/test.csv', encoding='Big5', header=None)\n",
    "test = test.replace('NR', '0')\n",
    "file = '0305-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "dic = {'w': w, 'scaler': scaler, 'selected_var' : selected_var}\n",
    "with open('model/'+file+'.pkl', 'wb') as f:\n",
    "    pickle.dump(dic, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240\n",
      "6.817278463460968\n"
     ]
    }
   ],
   "source": [
    "ans = pd.read_csv('data/sampleSubmission.csv', encoding='Big5')\n",
    "test_feature = 18\n",
    "total_test = []\n",
    "row, col = test.shape\n",
    "test_number = int(row/test_feature)\n",
    "print(test_number)\n",
    "for i in range(test_number):\n",
    "    df = test.iloc[i*test_feature:(i+1)*test_feature, 2:]\n",
    "    xs = df.values.ravel().astype(np.float)\n",
    "    xs = (scaler.transform([xs])[0])\n",
    "    xs = [xs[i] for i in range(len(xs)) if i in selected_var]\n",
    "    xs = np.concatenate(([1], xs))\n",
    "    val = np.dot(xs,w)\n",
    "    if val < 0:\n",
    "        val = (round(val,0))\n",
    "    else:\n",
    "        print(val)\n",
    "        break\n",
    "    ans.iloc[i,1] = val\n",
    "# ans.to_csv('data/'+file+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (5600,163) and (150,) not aligned: 163 (dim 1) != 150 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-1faf61c97f88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mxss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (5600,163) and (150,) not aligned: 163 (dim 1) != 150 (dim 0)"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "with open('model/0304-3.pkl', 'rb') as f:\n",
    "    dic = pickle.load(f)\n",
    "\n",
    "w = dic['w']\n",
    "scaler = dic['scaler']\n",
    "selected_var = dic['selected_var']\n",
    "\n",
    "\n",
    "val = np.column_stack(([1] * len(xss) ,xss))\n",
    "predict = np.dot(val,w)\n",
    "predict = np.array([max(0,predict[i]) for i in range(len(predict))])\n",
    "\n",
    "error = (predict-yss)\n",
    "plt.plot(error)\n",
    "\n",
    "outlier = [ i for i in range(len(error)) if abs(error[i]) >= 15]\n",
    "print(len(outlier))\n",
    "\n",
    "\n",
    "xss = [ xss[i] for i in range(len(xss)) if i not in outlier]\n",
    "yss = [ yss[i] for i in range(len(yss)) if i not in outlier]\n",
    "xss = pd.DataFrame(xss)\n",
    "\n",
    "print(len(a))\n",
    "plt.plot(sd_residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n",
      "9 0\n",
      "0 3\n",
      "9 1\n",
      "0 5\n",
      "0 6\n",
      "3 0\n",
      "3 1\n",
      "3 2\n",
      "3 3\n",
      "3 4\n",
      "3 5\n",
      "3 6\n",
      "3 7\n",
      "3 8\n"
     ]
    }
   ],
   "source": [
    "rm = set(range(0,164)) - set(selected_var)\n",
    "rm = list(rm)\n",
    "for i in rm:\n",
    "    print(int(i/18), i % 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[yss[i] for i in range(len(yss)) if i in outlier]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
